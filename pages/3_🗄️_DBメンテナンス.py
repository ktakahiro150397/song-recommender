"""
DBãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹ãƒšãƒ¼ã‚¸

ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®ç®¡ç†ã¨æ›²ã®å‰Šé™¤
"""

import streamlit as st
import pandas as pd
from pathlib import Path

from core.db_manager import SongVectorDB
from config import DB_CONFIGS

# ========== è¨­å®š ==========
DB_PATHS = {
    "Full": "songs_full",
    "Balance": "songs_balanced",
    "Minimal": "songs_minimal",
}

# ========== ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£é–¢æ•° ==========


def load_songs_as_dataframe(db: SongVectorDB, limit: int = 1000) -> pd.DataFrame:
    """DBã‹ã‚‰æ›²ä¸€è¦§ã‚’å–å¾—ã—ã¦DataFrameã«å¤‰æ›"""
    result = db.list_all(limit=limit)

    if not result["ids"]:
        return pd.DataFrame()

    data = []
    for i, song_id in enumerate(result["ids"]):
        metadata = result["metadatas"][i] if result["metadatas"] else {}
        data.append(
            {
                "é¸æŠ": False,  # ãƒã‚§ãƒƒã‚¯ãƒœãƒƒã‚¯ã‚¹ç”¨
                "ID": song_id,
                "source_dir": metadata.get("source_dir", ""),
                "filename": metadata.get("filename", ""),
                "æ¤œç´¢é™¤å¤–": metadata.get("excluded_from_search", False),
            }
        )

    return pd.DataFrame(data)


def delete_songs(song_ids: list[str]) -> tuple[int, list[str]]:
    """è¤‡æ•°ã®æ›²ã‚’å…¨DBã‹ã‚‰å‰Šé™¤"""
    success_count = 0
    errors = []

    for song_id in song_ids:
        try:
            # å…¨DBã‹ã‚‰å‰Šé™¤ï¼ˆFull/Balance/Minimalï¼‰
            for collection_name in DB_PATHS.values():
                db = SongVectorDB(collection_name=collection_name, distance_fn="cosine")
                db.delete_song(song_id)
            success_count += 1
        except Exception as e:
            errors.append(f"{song_id}: {str(e)}")

    return success_count, errors


def toggle_excluded_flag(song_ids: list[str], exclude: bool) -> tuple[int, list[str]]:
    """è¤‡æ•°ã®æ›²ã®æ¤œç´¢é™¤å¤–ãƒ•ãƒ©ã‚°ã‚’å…¨DBã§æ›´æ–°"""
    success_count = 0
    errors = []

    for song_id in song_ids:
        try:
            # å…¨DBã§æ›´æ–°ï¼ˆFull/Balance/Minimalï¼‰
            for collection_name in DB_PATHS.values():
                db = SongVectorDB(collection_name=collection_name, distance_fn="cosine")
                # æ—¢å­˜ã®ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
                song_data = db.get_song(song_id, include_embedding=False)
                if song_data and song_data.get("metadata"):
                    metadata = song_data["metadata"]
                    metadata["excluded_from_search"] = exclude
                    db.update_metadata(song_id, metadata)
            success_count += 1
        except Exception as e:
            errors.append(f"{song_id}: {str(e)}")

    return success_count, errors


def find_potential_duplicates(db: SongVectorDB, limit: int = 10000) -> list[tuple[str, list[str]]]:
    """
    æ›²åã®é¡ä¼¼æ€§ã‹ã‚‰é‡è¤‡ã®å¯èƒ½æ€§ãŒã‚ã‚‹æ›²ã‚’ã‚°ãƒ«ãƒ¼ãƒ—åŒ–
    
    Returns:
        [(åŸºæº–æ›²ID, [é¡ä¼¼æ›²IDãƒªã‚¹ãƒˆ]), ...] ã®ãƒªã‚¹ãƒˆ
    """
    import difflib
    
    all_songs = db.list_all(limit=limit)
    if not all_songs["ids"]:
        return []
    
    song_ids = all_songs["ids"]
    duplicates = []
    processed = set()
    
    for i, song_id in enumerate(song_ids):
        if song_id in processed:
            continue
            
        # ã“ã®IDã¨é¡ä¼¼ã—ã¦ã„ã‚‹ä»–ã®IDã‚’æ¢ã™
        similar_songs = []
        base_name = song_id.lower()
        
        for j, other_id in enumerate(song_ids):
            if i == j or other_id in processed:
                continue
                
            other_name = other_id.lower()
            # é¡ä¼¼åº¦ã‚’è¨ˆç®—ï¼ˆ0.7ä»¥ä¸Šã§é¡ä¼¼ã¨ã¿ãªã™ï¼‰
            similarity = difflib.SequenceMatcher(None, base_name, other_name).ratio()
            
            if similarity > 0.7:
                similar_songs.append(other_id)
                processed.add(other_id)
        
        if similar_songs:
            duplicates.append((song_id, similar_songs))
            processed.add(song_id)
    
    return duplicates


# ========== ãƒ¡ã‚¤ãƒ³ç”»é¢ ==========

st.set_page_config(
    page_title="DBãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹",
    page_icon="ğŸ—„ï¸",
    layout="wide",
)

st.title("ğŸ—„ï¸ DBãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹")
st.caption("Full/Balance/Minimal ã®3ã¤ã®DBã‚’åŒæœŸç®¡ç†")

# ã‚µã‚¤ãƒ‰ãƒãƒ¼: DBé¸æŠ
st.sidebar.header("è¨­å®š")

# ãƒªãƒ¢ãƒ¼ãƒˆChromaDBã‚µãƒ¼ãƒãƒ¼ã‚’ä½¿ç”¨ã™ã‚‹ãŸã‚ã€ã™ã¹ã¦ã®DBã‚’åˆ©ç”¨å¯èƒ½ã¨ã—ã¦æ‰±ã†
available_dbs = DB_PATHS

if not available_dbs:
    st.error("åˆ©ç”¨å¯èƒ½ãªDBãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
    st.stop()

selected_db_name = st.sidebar.selectbox(
    "è¡¨ç¤ºã™ã‚‹DB",
    options=list(available_dbs.keys()),
    index=0,
)

collection_name = available_dbs[selected_db_name]

# DBã‚’åˆæœŸåŒ–
try:
    db = SongVectorDB(collection_name=collection_name, distance_fn="cosine")
    total_count = db.count()
except Exception as e:
    st.error(f"DBåˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")
    st.stop()

# ã‚µã‚¤ãƒ‰ãƒãƒ¼: çµ±è¨ˆæƒ…å ±
st.sidebar.header("DBæƒ…å ±")
st.sidebar.metric("ç·ç™»éŒ²æ›²æ•°", f"{total_count:,}")
st.sidebar.caption(f"è¡¨ç¤ºä¸­: {selected_db_name}")
st.sidebar.caption("â€» å‰Šé™¤æ™‚ã¯å…¨DBã‹ã‚‰å‰Šé™¤")

# è¡¨ç¤ºä»¶æ•°è¨­å®š
limit = st.sidebar.number_input(
    "è¡¨ç¤ºä»¶æ•°",
    min_value=10,
    max_value=10000,
    value=total_count,  # å…¨ä»¶è¡¨ç¤ºã‚’ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã«
    step=100,
)

# æ¤œç´¢ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼
st.sidebar.header("æ¤œç´¢ãƒ»ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼")
search_query = st.sidebar.text_input(
    "IDã§æ¤œç´¢ï¼ˆéƒ¨åˆ†ä¸€è‡´ï¼‰",
    placeholder="ä¾‹: ãƒ•ã‚§ã‚¹ã‚¿",
)

source_dir_filter = st.sidebar.text_input(
    "Source Dirã§æ¤œç´¢",
    placeholder="ä¾‹: gakumas_mv",
)

# æ¤œç´¢é™¤å¤–ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼
show_excluded = st.sidebar.checkbox(
    "æ¤œç´¢é™¤å¤–æ›²ã‚’è¡¨ç¤º",
    value=True,
    help="æ¤œç´¢é™¤å¤–ãƒ•ãƒ©ã‚°ãŒç«‹ã£ã¦ã„ã‚‹æ›²ã‚‚è¡¨ç¤ºã—ã¾ã™",
)

# ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
if search_query or source_dir_filter:
    # ãƒ•ã‚£ãƒ«ã‚¿ãŒã‚ã‚‹å ´åˆã¯å…¨ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
    with st.spinner("å…¨ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰æ¤œç´¢ä¸­..."):
        df = load_songs_as_dataframe(db, limit=total_count)
else:
    # ãƒ•ã‚£ãƒ«ã‚¿ãŒãªã„å ´åˆã¯è¡¨ç¤ºä»¶æ•°åˆ¶é™
    with st.spinner("ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ä¸­..."):
        df = load_songs_as_dataframe(db, limit=int(limit))

if df.empty:
    st.warning("ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
    st.stop()

# ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
filtered_df = df.copy()

if search_query:
    filtered_df = filtered_df[
        filtered_df["ID"].str.contains(search_query, case=False, na=False)
    ]

if source_dir_filter:
    filtered_df = filtered_df[
        filtered_df["source_dir"].str.contains(source_dir_filter, case=False, na=False)
    ]

if not show_excluded:
    filtered_df = filtered_df[filtered_df["æ¤œç´¢é™¤å¤–"] == False]

st.info(
    f"è¡¨ç¤ºä¸­: {len(filtered_df):,} ä»¶ / å…¨ {len(df):,} ä»¶ï¼ˆDBå†…: {total_count:,} ä»¶ï¼‰"
)

# ãƒ‡ãƒ¼ã‚¿ã‚¨ãƒ‡ã‚£ã‚¿ãƒ¼ï¼ˆãƒã‚§ãƒƒã‚¯ãƒœãƒƒã‚¯ã‚¹ä»˜ãï¼‰
st.subheader("ğŸ“‹ æ›²ä¸€è¦§")

# å…¨é¸æŠãƒã‚§ãƒƒã‚¯ãƒœãƒƒã‚¯ã‚¹
col1, col2 = st.columns([1, 5])
with col1:
    select_all = st.checkbox("å…¨ã¦é¸æŠ", key="select_all")

# å…¨é¸æŠãŒæœ‰åŠ¹ãªå ´åˆã€å…¨ã¦ã®ã€Œé¸æŠã€åˆ—ã‚’Trueã«è¨­å®š
if select_all:
    filtered_df["é¸æŠ"] = True

edited_df = st.data_editor(
    filtered_df,
    column_config={
        "é¸æŠ": st.column_config.CheckboxColumn(
            "é¸æŠ",
            help="å‰Šé™¤ã™ã‚‹æ›²ã‚’é¸æŠ",
            default=False,
        ),
        "ID": st.column_config.TextColumn(
            "æ›²ID",
            width="medium",
        ),
        "source_dir": st.column_config.TextColumn(
            "Source Dir",
            width="small",
        ),
        "filename": st.column_config.TextColumn(
            "ãƒ•ã‚¡ã‚¤ãƒ«å",
            width="large",
        ),
        "æ¤œç´¢é™¤å¤–": st.column_config.CheckboxColumn(
            "æ¤œç´¢é™¤å¤–",
            help="ã“ã®ãƒ•ãƒ©ã‚°ãŒONã®æ›²ã¯æ¤œç´¢çµæœã‹ã‚‰é™¤å¤–ã•ã‚Œã¾ã™",
            default=False,
        ),
    },
    hide_index=True,
    width="stretch",
    height=500,
)

# å‰Šé™¤å‡¦ç†
st.subheader("ğŸ—‘ï¸ å‰Šé™¤")

selected_songs = edited_df[edited_df["é¸æŠ"] == True]["ID"].tolist()

if selected_songs:
    st.warning(
        f"âš ï¸ {len(selected_songs)} ä»¶é¸æŠä¸­ï¼ˆFull/Balance/Minimal å…¨ã¦ã‹ã‚‰å‰Šé™¤ã•ã‚Œã¾ã™ï¼‰"
    )

    col1, col2 = st.columns([1, 4])

    with col1:
        if st.button(
            "ğŸ—‘ï¸ é¸æŠã—ãŸæ›²ã‚’å‰Šé™¤",
            type="primary",
        ):
            with st.spinner("3ã¤ã®DBã‹ã‚‰å‰Šé™¤ä¸­..."):
                success_count, errors = delete_songs(selected_songs)

            if errors:
                st.error(f"å‰Šé™¤å®Œäº†: {success_count} ä»¶ / ã‚¨ãƒ©ãƒ¼: {len(errors)} ä»¶")
                with st.expander("ã‚¨ãƒ©ãƒ¼è©³ç´°"):
                    for err in errors:
                        st.text(err)
            else:
                st.success(f"âœ… {success_count} ä»¶ã‚’å‰Šé™¤ã—ã¾ã—ãŸ")

            st.rerun()

    with col2:
        with st.expander("é¸æŠä¸­ã®æ›²ã‚’ç¢ºèª"):
            for song in selected_songs:
                st.text(f"â€¢ {song}")
else:
    st.info("å‰Šé™¤ã™ã‚‹æ›²ã‚’ãƒã‚§ãƒƒã‚¯ã§é¸æŠã—ã¦ãã ã•ã„")

# æ¤œç´¢é™¤å¤–ãƒ•ãƒ©ã‚°ã®ç®¡ç†
st.subheader("ğŸ·ï¸ æ¤œç´¢é™¤å¤–ãƒ•ãƒ©ã‚°ç®¡ç†")

if selected_songs:
    st.info(f"ğŸ’¡ {len(selected_songs)} ä»¶é¸æŠä¸­")
    
    col1, col2 = st.columns(2)
    
    with col1:
        if st.button("âœ… æ¤œç´¢é™¤å¤–ã«ã™ã‚‹", type="secondary", use_container_width=True):
            with st.spinner("æ¤œç´¢é™¤å¤–ãƒ•ãƒ©ã‚°ã‚’è¨­å®šä¸­..."):
                success_count, errors = toggle_excluded_flag(selected_songs, True)
            
            if errors:
                st.error(f"æ›´æ–°å®Œäº†: {success_count} ä»¶ / ã‚¨ãƒ©ãƒ¼: {len(errors)} ä»¶")
                with st.expander("ã‚¨ãƒ©ãƒ¼è©³ç´°"):
                    for err in errors:
                        st.text(err)
            else:
                st.success(f"âœ… {success_count} ä»¶ã‚’æ¤œç´¢é™¤å¤–ã«ã—ã¾ã—ãŸ")
            
            st.rerun()
    
    with col2:
        if st.button("ğŸ”“ æ¤œç´¢é™¤å¤–ã‚’è§£é™¤", type="secondary", use_container_width=True):
            with st.spinner("æ¤œç´¢é™¤å¤–ãƒ•ãƒ©ã‚°ã‚’è§£é™¤ä¸­..."):
                success_count, errors = toggle_excluded_flag(selected_songs, False)
            
            if errors:
                st.error(f"æ›´æ–°å®Œäº†: {success_count} ä»¶ / ã‚¨ãƒ©ãƒ¼: {len(errors)} ä»¶")
                with st.expander("ã‚¨ãƒ©ãƒ¼è©³ç´°"):
                    for err in errors:
                        st.text(err)
            else:
                st.success(f"âœ… {success_count} ä»¶ã®æ¤œç´¢é™¤å¤–ã‚’è§£é™¤ã—ã¾ã—ãŸ")
            
            st.rerun()
else:
    st.info("æ¤œç´¢é™¤å¤–ãƒ•ãƒ©ã‚°ã‚’å¤‰æ›´ã™ã‚‹æ›²ã‚’ãƒã‚§ãƒƒã‚¯ã§é¸æŠã—ã¦ãã ã•ã„")

# é‡è¤‡æ¤œå‡ºã‚»ã‚¯ã‚·ãƒ§ãƒ³
st.divider()
st.subheader("ğŸ” é‡è¤‡æ›²æ¤œå‡º")

st.info("ğŸ’¡ æ›²åã®é¡ä¼¼æ€§ã‹ã‚‰é‡è¤‡ã®å¯èƒ½æ€§ãŒã‚ã‚‹æ›²ã‚’ã‚°ãƒ«ãƒ¼ãƒ—è¡¨ç¤ºã—ã¾ã™")

if st.button("ğŸ” é‡è¤‡æ¤œå‡ºã‚’å®Ÿè¡Œ", type="secondary"):
    with st.spinner("é‡è¤‡ã‚’æ¤œå‡ºä¸­..."):
        duplicates = find_potential_duplicates(db, limit=total_count)
    
    if duplicates:
        st.success(f"âœ… {len(duplicates)} ã‚°ãƒ«ãƒ¼ãƒ—ã®é‡è¤‡å€™è£œã‚’æ¤œå‡ºã—ã¾ã—ãŸ")
        
        for idx, (base_song, similar_songs) in enumerate(duplicates, 1):
            with st.expander(f"ã‚°ãƒ«ãƒ¼ãƒ— {idx}: {base_song} + {len(similar_songs)} ä»¶"):
                st.write(f"**åŸºæº–æ›²:** {base_song}")
                st.write(f"**é¡ä¼¼æ›² ({len(similar_songs)} ä»¶):**")
                for similar in similar_songs:
                    st.text(f"  â€¢ {similar}")
                
                st.caption("ğŸ’¡ é‡è¤‡ã¨æ€ã‚ã‚Œã‚‹æ›²ã‚’ä¸Šã®è¡¨ã§é¸æŠã—ã¦ã€å‰Šé™¤ã¾ãŸã¯æ¤œç´¢é™¤å¤–ã—ã¦ãã ã•ã„")
    else:
        st.info("é‡è¤‡å€™è£œã¯è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")

# ãƒªãƒ•ãƒ¬ãƒƒã‚·ãƒ¥ãƒœã‚¿ãƒ³
if st.sidebar.button("ğŸ”„ å†èª­ã¿è¾¼ã¿"):
    st.rerun()
